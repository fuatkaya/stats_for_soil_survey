---
title: 'Homework assignment: _Range in Characteristics_ for Horizon Data'
author: "Andrew Brown; based on prior work by Dylan Beaudette & Jay Skovlin"
date: "`r Sys.Date()`"
output: 
  html_document:
    keep_md: no
    number_sections: yes
    toc: yes
    toc_float:
      collapsed: yes
      smooth_scroll: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

***

# The "Scenario"

You have a collection of pedons that have been correlated to a soil series or component that you would would like to compute _Range in Characteristics_ (“low-rv-high” values; RIC) for.
 
***

# Objective

For your homework, we ask you to calculate Range in Characteristic(s) for a soil series or component. 

To do this, you will assign _Generalized Horizon Labels_ to pedons from your area of responsibility. These labels will be a grouping variable that helps you to determine  the RIC for one (or more) properties of your choice. 

One way we can create Generalized Horizon Labels is by _matching patterns in the field horizon designations_ and creating _simpler_ labels for more complex groups of horizon designation. We have started to call this assignment of _generalized labels_ to horizons: _micro-correlation_. 

NOTE: There are some __Homework Tips__ at the end of the document to help you get going on modifications for your own analyses.

Use this [R file](genhz_homework.R) containing just the code from this document to start your own analysis. 

## So, what do I have to hand in?

1. A SoilProfileCollection plot - showing the Generalized Horizon Labels as horizon colors and field designation as the labels along the side of each profile. 

2. Table of _Range in Characteristics_ for your selected property in each _Generalized Horizon Label_.
 
Alternately, you may do the entire assignment in a _.Rmd_ file (R Markdown) and submit the "knitted" HTML result.

Send the results to your mentor with your first and last name in the file name (for example:`genhz_homework_BrownAndrew.html`). 

# Instructions

1. Query NASIS database to __load your selected set__ with some pedons.

2. __Create a _subset_ (in R)__ of soils to summarize (call it `pedons`). You should have about `n = 20` for a managable demo that fits nicely in a SoilProfileCollection plot, but you are welcome to try the same routines on larger sets.

3. __Decide on "prototype" horizon designation scheme.__ Think of the "prototype" as as set of general horizon labels that are related -- like the list of horizon designations that you provide for the Range in Characteristics in an OSD, or the list of layers you include in a SSURGO component.

4. __Inspect the field horizon designations__ (look at the pedons in R or NASIS, if needed). Think about which field horizon designation(s) should correlate to each "prototype" horizon.

5. __Write a set of regular expressions (REGEX patterns)__ (you'll need _one pattern per generalized horizon_) to do the correlations you thought about in *#4*. HINT: Use `generalize.hz()` to apply the patterns to your data. For instance: `pattern = "A|B|C"` will match all horizons containing "A", "B" OR "C" and `pattern = "^A"` matches horizons that _start with_ "A". There are many other REGEX operations. See http://regular-expressions.info for more details.

6. __Cross-tabulate__ your Generalized Horizon Labels against the field horizon designations. This will show a table of the mapping from "old" to "new" ("field" to "correlated").

7. __Check if any horizon designations were _NOT_ assigned a label__ (have label "not-used"). At a minimum you should be able to answer the question: "_Which horizons were not assigned?_" Bonus points if you can answer "_Why [those horizons] weren't assigned?_"

8. __Revise your patterns__ as needed. You don't need to get them _perfect_ but we want you to think about how you could/would "improve" them, especially if they don't work as intended. 

9. __Do a statistical summary on your horizon groups.__ You can use the example given below for `loafercreek` (mean/sd/min/max clay content) or do something else of interest to you. At a minimum for a proper "summary" you should return _at least one value_ for _each generalized horizon label_. That value can, _for some groups_, be `NA`, depending on your data and summary statistic of choice. See the example below that calculates mean, standard deviation and several quantiles of clay content for each generalized horizon.

_Be prepared to discuss issues you had with your mentor. In particular, what "decisions" did you have to make that might have influenced your final correlations and range in characteristics?_

***

## This document is an example

This document takes you through a demo of the homework assignment using a subset of the `loafercreek` dataset from the _soilDB_ package. You are encouraged to run through the code with `loafercreek` before attempting it on your own data. 
After reviewing this workflow, and with the help of your mentor, you should be able to apply this technique to your own data.
 
This assignment integrates several R/data analysis skills as well as brings on the "Great Unknown" of NASIS data inputs from across the country. With this type of uncharted territory, there is a lot of room for learning _new_ things ... and dealing with _new problems_. If your code does not work at first, do not be discouraged. Feel free to contact Andrew Brown (_andrew.g.brown@usda.gov_), or your assigned mentor, if you have questions, issues or comments.

 
# Getting started with Loafercreek

First, you will read over and run all the code in this document using the first 20 pedons from `loafercreek` as a demonstration. This will help you get comfortable with the process. Then you will apply the same strategy to NASIS pedons from your area of responsibility, adjusting patterns and summaries as needed. 

When it comes time, you will replace this next block of code with code to get your own data.

```{r, message=FALSE, warning=FALSE}
library(aqp)
library(soilDB)

# load sample `loafercreek` data from the soilDB package
data("loafercreek")

# keep only the first 20 pedons
pedons <- loafercreek[1:20, ]

# plot profile sketches
par(mar=c(0,0,2,1))
plot(pedons, name='hzname', print.id=FALSE)
```

# _Generalized Horizon Labels_

Why use Generalized Horizon Labels? 

We use Generalized Horizon Labels (GHL) to simplify the grouping in our input data. As soil scientists we put a lot of effort into our descriptions. Specifically, we try hard to describe _changes in profiles_ with corresponding _changes in horizons_. However, we don't all necessarily have the same opinions on how that should be done. We _generalize_ across profile descriptions, to deal with variation in:

 * description style / horizons designations used
 
 * horizon depths / boundaries
 
 * number of horizons described
 
When creating summaries of data we need a way to "relate" observations of _particular_ horizons from _particular_ pedons back to the _typical_ set of horizons found in the "group" the data belong to (e.g. a series or a component). 

Maybe we could look use all the _unique_ horizon designations in the data? 

And then create a summary for each group?

```{r}
# tabulate hzname
table(pedons$hzname)

# these are the _unique_ horizon designations in our subset `pedons`
unique(pedons$hzname)
```

With most decent-sized datasets, you will have a __lot__ of groups when taking this simple approach to grouping.

Here we have `r length(unique(pedons$hzname))` different horizon designations. Nobody would attempt to make _separate_ ranges for each unique group, especially with such a small amount of data in some of the groups.

Depending on things like depth class or the nature of the parent material, the number of horizon RICs provided in a series or component will vary. 

Many series concepts, especially older ones, provide RICs for only a couple _very_ generalized horizons (say, just an A and a Bt in a very deep soil) and avoided providing ranges for transitional horizons/vertical subdivisions. More "modern" descriptions might have more layers broken out, but there are diminshing returns with this. _More subdivision_ does not necessarily mean _more accurate representation_ of the aggregate entity. But this is, of course, a balance. 

The great thing about the GHL approach is that you can "test" the effect of adding/removing groups. Then you can decide if it adds interpretive value (i.e. a layer with "significantly" different properties) to have more or less groups based on the data you have.

## Correlation 

_Correlations_ can be made at various levels. Many of our major decisions are made at the component or pedon level.

With Generalized Horizon Labels, correlation decisions are being made on a horizon basis (in addition to at the pedon level), so we call it "micro-correlation." In this process, we determine what data from each pedon contributes to each Range in Characteristics for the group the pedon is a member of.  This has always implicitly been a part of Soil Correlation -- we are just making it _explicit_ and _reproducible_ by using R to track our decisions and facilitate analysis. This approach is also _appealing_ because we conventionally give ranges in terms of horizon designations (OSD RICs, component layers). 
 
A simple micro-correlation would be: "this transitional AB horizon has 'A' as the first designation so it is be more like an 'A' than a 'Bt' horizon of series Alpha". 

Programatically grouping horizon observations by designation is an excellent way to _begin_ to explore the properties of a set of profiles. You can (and should) look at more than just horizon designation. REGEX based pattern matching is really only a first pass micro-correlation, and often unusual data sneak through the cracks. There is no reason why you can't take into account other properties. 

A more nuanced micro-correlation would be: "Horizon Y should be included in the RIC for Bt horizons of Series Z because it occurs in the depth range of 31 to 65 cm, has clay films, a 5YR hue and 32% clay, even though the horizon designation is "BAt". Most other BAt horizons from Series Z are typically less red and/or have less clay."

### Micro-correlation

To "micro-correlate," you first need to come up with a "prototype" scheme for the soil you are studying. Essentially this is the list of horizon labels that occurs in your hypothetical, idealized, "typical" soil.

This could be, for instance, the horizons that occur in the OSD/Type location/TUD pedon or some generalization of them. 

Then you need to produce a set of REGEX patterns that correlate the field-observed horizon designations to your prototype horizons. 

Let's take a look at the horizon designations from the Loafercreek OSD:

```{r}
l <- fetchOSD('loafercreek')
l$hzname
```

We might not be able to produce a unique RIC for each of those subdivisions of the Bt. And we probably don't want to, even if we could. So we will have to generalize. 

Consider this: multiple layers or horizons can have same/similar ranges in characteristics, but if the ranges are exactly the same for all important properties... one could argue there is little _interpretive value_ to splitting out two where you could have one that performs "just as well." If you can't say how that potential new layer is different, you probably don't have the necessary data to justify including it. 

#### The "Prototype" Horizon Scheme

Here is an example of a prototype for horizonation in a soil concept. It is a generalization of the labels we found in the Loafercreek OSD layers -- and represents what we might find described in a series RIC or in Component Horizons. 

Our prototype labels include an A horizon, upper transitional horizon, argillic horizon, and a bedrock contact:

```{r}
# create 4 generalized horizon labels: A, upper transitional, argillic and bedrock
prototype.labels <- c('A',
                      'BA',
                      'Bt',
                      'Cr')
```

Having just a single group for the argillic horizon (Bt) versus splitting out upper and lower (Bt1/Bt2), for instance, would be a great analysis to evaluate for your own extensions of this demo. We are deliberately keeping the example _very_ general.

#### Regular Expressions

The vector `prototype.labels` has `r length(prototype.labels)` values in it. Therefore, `patterns.to.match` must also contain `r length(prototype.labels)` patterns.

Define the paired patterns for each `prototype.label`

```{r}
# REGEX rules describing mapping from field data to prototype.labels
patterns.to.match <- c('^A',
                      '^B.*[^Ct]$',
                      '.*B.*t.*',
                      'Cr|R')
```

Here is a brief explanation of the function of each of the 4 patterns:

 1. If the horizon designation starts with A, it goes in the "A" label
 
 2. If the horizon designation starts with B, but does not contain "C" or "t", it goes in the "BA" label
 
 3. If the horizon designation contains "B" and "t", it goes in the "Bt" label
 
 4. If the horizon contains "R" or "Cr", it goes in the "Cr"/bedrock label
 
[More information about regular expressions](https://www.regular-expressions.info/)

#### `generalize.hz()`

To summarize the previous two subsections, we created:

 * `r length(prototype.labels)` Generalized Horizon Labels (`prototype.labels`); and,
 
 * `r length(prototype.labels)` regular expression patterns (`patterns.to.match`) to assign data to (`prototype.labels`)

We use the `aqp` function `generalize.hz()` to apply the patterns in `patterns.to.match` to `pedons$hzname` and return the corresponding new _Generalized Horizon Label_ for horizons where a match is made. Importantly, the label for the last of the set of patterns to match is returned -- so if the first and fourth pattern match the same horizon, only the fourth label is assigned.

Note `loafercreek` (and other SPCs coming out of `fetchNASIS()`) already have a horizon-level variable called `genhz` which has the contents of the NASIS Pedon Horizon Component Layer ID by default (when populated). At the end of this document there is a guide for importing the labels assigned by R into NASIS.
 
Since we don't want to overwite those data that came out of NASIS at this point, we will create a new horizon-level variable `newgenhz` to hold our preliminary Generalized Horizon Label assignments.

```{r}
pedons$newgenhz <- generalize.hz(x=pedons$hzname, new=prototype.labels, pat=patterns.to.match)
```

#### Cross-tabulate results

That's it. We have generalized the horizons. Let's take a look at how our patterns did. 

We "cross-tabulate" the results of `generalize.hz()` with the input data to see how our field-data got mapped to the new labels.

In particular we want to see if any horizons in the input data got "missed" by our patterns or if horizons are getting correlated to labels we did not expect.

```{r}
oldvsnew <- addmargins(table(pedons$newgenhz, pedons$hzname))
oldvsnew
```

In this table you see that _columns_ correspond to all the different horizon designations found _in the original data_.

And the _rows_ correspond to our _Generalized Horizon Labels_. 

The numbers in each cell show how many observations (horizons) have that combination of field designation _and_ Generalized Horizon Label.

Note that the 'not-used' class is the default result when _none of the patterns match_. You can set alternate values for no-match case with `generalize.hz(..., non.matching.code = 'alternate-not-used-code').`

```{r}
# find which columns are greater than zero in row 'not-used'
col.idx.not.used <- which(oldvsnew['not-used',] > 0)

# what column indexes (field horizon designations) did not get mapped onto a row (generalized hz label)?
col.idx.not.used

# show just those columns
oldvsnew[, col.idx.not.used]
```

For the `loafercreek` example, we see that 5 "BC", 4 "C" and 2 "Oi" horizons did not match any pattern.

Since we require a "t" to be in the "Bt" group, and "C" is not allowed in the "BA" group, the "BC" falls through the cracks. Likewise, "C" and "Oi" did not have patterns created to match them.

So, let's say we've decided we don't want these 'not-used' horizons lumped with our 'A', 'BA', 'Bt' OR 'Cr' groups. Therefore, we either need to add _additional_ pairs of labels and patterns to match them *OR* leave them as 'not-used'.

### Discussion & Revision (Applied to Loafercreek)

Since there are only a handful of observations for the C's and O's (4 and 2 of each, respectively) they may not be particularly "representative" for the "Loafercreek series." 

If that is the case, it is probably OK that they are _not_ included in a group label (and they stay 'not-used'). But remember we are only using a portion of the `loafercreek` data for this demo, so take that conclusion wiht a grain of salt. Let's continue for now.

The lack of clay films is apparently a commonality between "BC" and "C" -- could they be combined?

On these parent materials, C horizons were sometimes used to describe borderline fragmental layers derived from residual bedrock. Roots may be able to enter in >10% of the volume via cracks/soil material between fragments. On the other side of the spectrum, some in-situ weathered rock doesn't show a whole lot in the way of clay films and commonly doesn't meet cementation criteria for bedrock. Both "modes" could exist within this set of unmatched BC and C horizons.

If you were trying to apply generalized labels to Loafercreek, you could test the idea that they have an unusually large volume of rock fragments (`horizons(loafercreek)$total_frags_pct`) -- maybe some of them do and some don't. 

You could compare the range derived for your "C" to the range for "BC" to help you decide if they are similar to one another or not (if you were considering lumping them together). Do they have similar clay contents and colors?

We will lump them for this demo, since it will be a small group with this subset no matter what. If we had more observations of the `Oi` we could estimate its thickness using the transition probabilities between generalized horizon labels. In this case (Loafercreek), they are seldom more than a few centimeters thick and are not much of an "O" horizon to speak of, so we have left this class out for now.

We apply the patterns as before, but create another Generalized Horizon Label variable `pedons$newgenhz2` to hold the new result. This is to illustrate that the development of _Generalized Horizon Label_ patterns is an _iterative process_ and your first pass may be far from perfect. 

For a new `BC` label pattern we match all horizons that contain `C` and have zero or more characters that are NOT `t` and put them in the `BC` group. 

Because of the ordering of patterns, `Cr` will be matched by patterns 4 and 5, but only the label for pattern 5 (`Cr`) will be assigned. Let's assign the new labels:

```{r}
# create 5 generalized horizons: A, upper transitional, argillic, lower-transitional and bedrock
prototype.labels.v2 <- c('A',
                         'BA',
                         'Bt',
                         'BC',
                         'Cr')

# REGEX rules describing mapping from field data to prototype.labels
patterns.to.match.v2 <- c('^A',
                          '^B.*[^Ct]$',
                          '.*B.*t.*',
                          'C[^t]*',
                          'Cr|R')

# use generalize.hz() to apply a set of patterns and paired labels
# to the `pedons$hzname` character vector containing field designations
pedons$newgenhz2 <- generalize.hz(x=pedons$hzname, new=prototype.labels.v2, pat=patterns.to.match.v2)
```

Now we cross-tabulate again, showing only `not-used` data.

```{r}
# create a second cross-tabulation, using the updated genhz
oldvsnew2 <- addmargins(table(pedons$newgenhz2, pedons$hzname))

# find which table columns are greater than zero in row 'not-used'
col.idx.not.used <- which(oldvsnew2['not-used',] > 0)

# show just those columns
oldvsnew2[, col.idx.not.used]
```

As you can see, the `BC` and `C` horizons that were `not-used` before are now correlated to the `BC` group.

The only horizon data that are `not-used` are the 2 `Oi` horizons. You can compare `pedons$newgenhz2` with the labels we created before `pedons$newgenhz` and the labels loaded from NASIS Pedon Horizon Component Layer ID `pedons$genhz` to see the differences.

```{r eval=F}
# check for equality (assignment 1 versus assignment 2)
pedons$newgenhz == pedons$newgenhz2
```

## Visualizing Generalized Horizon Labels

Let's recreate the graph we did at the beginning, only now we will color horizons in the plot based on their _Generalized Horizon Label_. This will make it clear how our patterns simplified the grouping of the pedon horizon data, and also provide us with a visual check on our logic. 

Compare the coloring (based on `pedons$newgenhz2`) with the field horizon designations (`pedons$hzname`) to the right of each profile.

```{r}
# plot profile sketches - first 20 profiles; color by gen hz.
par(mar=c(0,0,2,1))
plotSPC(pedons, name='hzname', color='newgenhz2', print.id=FALSE)
```

Here are a few things that are evident for the Loafercreek example:
_Our upper transitional horizon ('BA' group) captures 'BA' as well as 'Bw'. The bulk of the profile is the argillic horizon (Bt). Some pedons have lower gradational horizons (BC or C). Most pedons have Cr or Cr over R, but we treat the paralithic and lithic contacts equivalently for this demo._

In RStudio you can "Export" a plot from the drop down menu at top of "Plots" pane (after you run the code to make the plot). 

Or save the plot using R code. See `?pdf`, `?jpg`, `?dev.off` helpfiles for how to capture output sent to a graphics device (by `plot()`) and save it to a file instead of sending it to the "Plots" pane.

We compare the the number of _original_ horizon designations from the field data with the number of unique _generalized_ horizon labels.

```{r}
# original field data (27 levels)
length(unique(pedons$hzname))

# new generalized data (6 levels, including not-used)
length(unique(pedons$newgenhz2))
```

We went from 27 levels or "groups" in the field data to 6 groups "as correlated." Six groups (5 soil horizons + bedrock) is a more reasonable "prototype" if we are trying to write a RIC for an OSD or component. 

Let's look at how we can generate RICs based on the labels we assigned (and subsequently revised).

## Statistical Summaries by Generalized Horizon Label

Here we use the _split-apply-combine_ strategy to produce statistical summaries for each of our generalized horizons. 

We divide our horizon data into "pieces" using the last _Generalized Horizon Labels_ we assigned (`pedons$newgenhz2`) as the grouping variable. Then we do some statistics on each "piece" and combine the results for review.

 * [Split-Apply-Combine Strategy for Data Analysis](https://www.jstatsoft.org/article/view/v040i01) - Dr. Hadley Wickham

```{r}
# get the horizon data frame out of the SPC
hzdata <- horizons(pedons)

# make a list of data frames from horizons, split based on the Generalized Horizon Labels (`f`)
genhz.list <- split(hzdata, f = hzdata$newgenhz2)

# use lapply() to apply a function to each element of `genhz.list`
#  the anonymous function calculates some summary statistics on each subset dataframe (`d`)
res <- lapply(genhz.list, FUN = function(d) {
  # the variable 'd' contains the dataframe with all the data for a particular  Generalized Horizon Label
  
  # calculate mean clay content, removing NA and rounding to one decimal
  # we suppressWarnings() for the cases where all d$clay are NA (O horizons, bedrock)
  suppressWarnings(clay.mean <- round(mean(d$clay, na.rm=T),1))
  
  # calculate standard deviation of clay content, removing NA and rounding to one decimal
  suppressWarnings(clay.sd <- round(sd(d$clay, na.rm=T),1))
  
  # calculate min clay content, removing NA
  suppressWarnings(clay.min <- min(d$clay, na.rm=T))
  
  # calculate max clay content, removing NA
  suppressWarnings(clay.max <- max(d$clay, na.rm=T))
  
  # calculate some selected quantiles (5th, median, 95th)
  suppressWarnings(clay.q <- quantile(d$clay, 
                                      probs=c(0.05,0.5,0.95), 
                                      na.rm=T)) 
  
  # What other summary statistics could you calculate? 
  # e.g. quantile() for use 5th 50th 95th percentiles 
  
  # CHECK FOR NON-NaN (NOT a NUMBER) mean result; 
  # if NaN, na.rm removed all records. Return NA
  if(!is.nan(clay.mean)) {
    return(data.frame(claymean=clay.mean, claysd=clay.sd, 
                      claymin=clay.min, claymax=clay.max,
                      clayq5=clay.q[1], clayq50=clay.q[2], 
                      clayq95=clay.q[3], n.obs=length(d$clay)))
  } else { 
    return(data.frame(claymean=NA, claysd=NA, 
                      claymin=NA, claymax=NA, 
                      clayq5=NA, clayq50=NA, 
                      clayq95=NA, n.obs=length(d$clay)))
  }
})

# take each list element (a data frame) and rbind them together to make one data frame
res.df <- do.call('rbind', res)

# show results
res.df
```

This is an implementation of a _Range in Characteristics_ for clay content. We are using _very_ Generalized Horizon Labels and calculating summary statistics (mean, sd, min, max, various quantiles) for just a single property within each Generalized Horizon Label.

*Question:* _What values (calculated for the Loafercreek example) might be best for a RIC (LOW-RV-HIGH)? Why?_

*Question:* _How do Loafercreek clay content mean, standard deviation, minimum and maximum compare to the quantiles? Why?_

You can save the table as a _.csv_ or _.Rda_ (Rdata object - in a file) file using `write.csv()` or `save()`. 

```{r, eval=F}
# save a text-based (comma-separated) version of the result table
write.csv(res.df, file = "Your_RIC_table_output.csv")

# save a binary file representation of the R object containing result table
save(res.df, file = "Your_RIC_table_output.Rda")
```

To continue with your work, you might need these groups to be populated in NASIS Component Layer ID -- learn how to do that next.

# Saving Generalized Horizon Labels to NASIS

In order to use/save Generalized Horizon Labels in further analysis or perform _manual_ adjustments, they need to be saved externally. 

If you are a NASIS user then the following code will create a text file that can be read by NASIS and stored in the `dspcomplayerid` field of the _Pedon Horizon_ table. 

The NASIS _Pedon Horizon_ Calculation "_Update horizon group aggregations using a text file_" uses a text file `C:/data/horizon_agg.txt`, which contains each `phiid` (pedon horizon unique record ID) paired with a label to assign.

Here is the code to make a NASIS horizon group aggregation text file. This will write `newgenhz` out to the `horizon_agg.txt` file out for each `phiid` in your object `pedons`. 

```{r}
# set output path
rules.file <- 'C:/data/horizon_agg.txt'

# write blank output (gets rid of any old assignments saved in the file)
write.table(data.frame(), file=rules.file, row.names=FALSE,
            quote=FALSE, na='', col.names=FALSE, sep='|')

# extract horizon data.frame
h <- horizons(pedons)

# strip-out 'not-used' genhz labels and retain horizon ID and genhz assignment
h <- h[which(h$newgenhz != 'not-used'), c('phiid', 'newgenhz')]

# append to NASIS import file
write.table(h, file=rules.file, row.names=FALSE, quote=FALSE,
            na='', col.names=FALSE, sep='|', append=TRUE)
```

To import the file, run NASIS _Pedon Horizon_ Calculation "_Update horizon group aggregations using a text file_."

Some people prefer to adjust assignments in R while others prefer to make adjustments after loading the data into NASIS. Some combination of the two may be required depending on the type and extent of adjustments that need to be made. 

Typically, NASIS is good for making final _specific_ changes to relatively small numbers of micro-correlation decisions, whereas wholeseale re-assignments that affect _many_ records in a consistent/programmatically-discernible way can be implemented much more efficiently in R.

# Homework Tips

Use `fetchNASIS()` to get pedons from your selected set. 

```{r eval=FALSE}
# then load data from the NASIS selected set into an R object called `pedons`
pedons <- fetchNASIS(from='pedons')
```

Of course, you first need to query some from your NASIS Local Database to have them in there.

Then subset your `fetchNASIS()` result to create a smaller group of pedons, called `pedons`. 

```{r eval=FALSE}
# optionally subset the data, FOR INSTANCE: by taxon name - replace Loafercreek with your taxon name
pedons <- pedons[grep(pattern='Loafercreek', x = f$taxonname, ignore.case=TRUE), ]
```

Instead of using a hard-coded numeric index (for example: `1:20`), you could subset your selected set using text-matching on a site/pedon attribute, for example, __taxon name__. 

To subset on __taxon name__, we used the function `grep()` to return just the numeric indices where `x = f$taxonname` matches our pattern (`pattern='Loafercreek'`). We set `ignore.case=TRUE` so we will match "LOAFERCREEK", "loafercreek" and "Loafercreek" -- along with any other oddly-capitalized variants that might exist. There are numerous other attributes that we could have subsetted on. Finally, we use the _data.frame_ notation for subsetting a _SoilProfileCollection_.

For this assignment, you need to do some sort of subsetting of your selected set using R -- but it does not need to be complex. 

Use _any_ site or horizon level attribute. See the function `aqp::subsetProfiles()` for a slick way to do this for site- or horizon-level variables.

Now that you have seen the full demonstration and read the tips for applying this workflow to your own data, please return to the top of the document. 

Run the code and perform analysis for your own pedons instead of `loafercreek`. Consider the results and discussion that were provided for Loafercreek, BUT instead, consider the conditions in _your_ data and adjust as needed. Discuss any issues you may have with your mentor.

***

__This document is a demonstration of concepts from the presentation "Soil Data Aggregation in R" found [here](http://ncss-tech.github.io/AQP/presentations/ghl-aggregation.html).__

__The contents are based on the 'Assigning and Using Generalized Horizon Labels' tutorial found [here](http://ncss-tech.github.io/AQP/aqp/gen-hz-application.html).__