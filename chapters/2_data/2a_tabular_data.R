library(knitr, quietly=TRUE)

opts_chunk$set(message=FALSE, warning=FALSE, background='#F7F7F7', fig.align='center', fig.retina=2, dev='png', tidy=FALSE, verbose=FALSE, antialias='cleartype', cache=FALSE)

# options for R functions
options(width=100, stringsAsFactors=FALSE)

library(ggplot2)
library(dplyr)

data("us_ss_timeline", package = "soilDB")

test <- as.data.frame(table(us_ss_timeline$year), stringsAsFactors = FALSE)

names(test)[names(test) %in% c("Var1", "Freq")] <- c("year", "Count")
test <- mutate(test, 
               year = as.numeric(year)
               )



g1 <- ggplot(test, aes(x = year, y = Count)) +
  geom_area(alpha = 0.7) + 
  ylim(0, max(test$Count, na.rm = TRUE) * 1.5) +
  scale_x_continuous(breaks = seq(1880, 2030, 8)) +
  # theme(aspect.ratio = 1) + 
  xlab("Year") +
  ggtitle("Number of Published US Soil Survey Manuscripts by Year")

g2  <- ggplot(test, aes(x = year, y = cumsum(Count))) +
  geom_area(alpha = 0.7) + 
  ylim(0, max(cumsum(test$Count), na.rm = TRUE) * 1.5) +
  scale_x_continuous(breaks = seq(1880, 2030, 8)) +
  # theme(aspect.ratio = 1) +
  xlab("Year") + ylab("Count") +
  ggtitle("Cumulative Number of Published US Soil Survey Manuscripts by Year")

# gridExtra::grid.arrange(g1, g2, ncol = 1)


pedons <- read.csv("https://raw.githubusercontent.com/ncss-tech/stats_for_soil_survey/master/data/pedons.csv", stringsAsFactors = FALSE)
pedons <- filter(pedons, obs_year %in% 1950:2018) %>%
  mutate(year = obs_year,
         lab = FALSE,
         Count = n_peiid
         )

labpedons <- read.csv("https://raw.githubusercontent.com/ncss-tech/stats_for_soil_survey/master/data/labpedons.csv", stringsAsFactors = FALSE)
labpedons <- filter(labpedons, obs_year %in% 1950:2018) %>%
  mutate(year = obs_year,
         lab = TRUE,
         Count = n_peiid
         )


g3 <- ggplot(pedons, aes(x = year, y = Count)) + 
  geom_area(aes(fill = lab), stat = "identity") + 
  geom_area(data = labpedons, aes(x = year, y = Count, fill = lab), stat = "identity") +
  ylim(0, max(pedons$Count, na.rm = TRUE) * 1.2) +
  ylab("Count") + xlab("Observation Year") +
  scale_x_continuous(breaks = seq(1880, 2030, 8)) +
  ggtitle("Number of Pedons per Year") 

g4 <- ggplot(pedons, aes(x = year, y = cumsum(Count))) + 
  geom_area(aes(fill = lab), stat = "identity") +
  ylim(0, max(cumsum(pedons$Count), na.rm = TRUE) * 1.2) +
  ylab("Count") + xlab("Observation Year") +
  scale_x_continuous(breaks = seq(1880, 2030, 8)) +
  ggtitle("Cumulative Number of Pedons per Year")

gridExtra::grid.arrange(g1, g3, ncol = 1)


  # Using the concatenate function we can create the following character and logical vectors
  # character vector: taxonomic subgroup
  subgroup <- c("typic haplocryepts","andic haplocryepts","typic dystrocryepts")  
  subgroup
  
  # logical vector: boolean field for presence or absence of andic soil properties diagnostic feature
  andic <- c(FALSE, TRUE, FALSE) 
  andic
  
  # Take our two character and logical vectors and convert them into a more useful dataframe.
  # we'll use the data.frame() function to glue these two vectors together into object 'd'
  d <- data.frame(subgroup, andic)
  
  # note that characters are converted to factors
  # what is a factor?
  str(d)

  # get the column names of a dataframe
  names(d)
  # we can use 'names()' and 'c()' to rename the columns in a dataframe
  names(d) <- c('tax_subgroup', 'andic.soil.properties')
  d

  # format: dataframe_name[rows, columns]
  d[1, ] # first row of dataframe
  d[, 1] # first column of dataframe
  d[2, 2] # second row, second column
  
  # In dataframes we can also use the '$' symbol to reference vector columns within a specific dataframe object
  d$tax_subgroup
  
  # Other useful functions for checking objects and working with dataframes
  # the structure 'str()' function will show you the structure of an object and the data types of the vectors within it
  str(d)
  # 'class()' will tell you the object type or data type
  class(d)
  # use 'colnames()' to get a vector of column names from a dataframe
  colnames(d)
  # ncol and nrow give dimensions
  ncol(d)
  nrow(d)
  
  # building on what we've learned above, we can use the square bracket notation on a dataframe to re-order columns
  d <- d[ ,c('andic.soil.properties', 'tax_subgroup')]
  d
  # another way we could do this is to use the column indexes within the concatenate function
  d <- d[ , c(2,1)]

library(diagram, quietly=TRUE)
# reset figure margins
par(mar = c(1, 1, 1, 1))

# simple diagram of the pedon data structure
names <- c("Site", "Siteobs", "Pedon", "Horizon")
M <- matrix(nrow = 4, ncol = 4, byrow = TRUE, data = 0)
M[4, 3] <- M[3, 2] <- M[2, 1] <- ""
pos <- cbind (c(1, 1, 1, 1))
plotmat(M, pos = pos, name = names, lwd = 1, box.lwd = 2, cex.txt = 0.8, box.size = 0.1, box.type = "square", box.prop = 0.4, mx=-0.2)

# parallel simplified SPC structure
names <- c("Site-level", "Horizon-level")
M <- matrix(nrow = 2, ncol = 2, byrow = TRUE, data = 0)
 M[2, 1] <- ""
#pos <- cbind (c(2, 2))
plotmat(M, pos = c(1, 1), name = names, lwd = 1, box.lwd = 2, cex.txt = 0.8, box.size = 0.14, box.type = "square", box.prop = 0.75, mx=0.3, my=-0.1, add=TRUE)

# add arrows to the diagram
arrows(0.42, 0.1, x1=0.65, y1=0.1, length = 0.25, code=2, lwd=2, angle = 15)
arrows(0.42, 0.35, x1=0.65, y1=0.54, length = 0.25, code=2, lwd=2, angle = 15)
arrows(0.42, 0.61, x1=0.65, y1=0.61, length = 0.25, code=2, lwd=2, angle = 15)
arrows(0.42, 0.87, x1=0.65, y1=0.68, length = 0.25, code=2, lwd=2, angle = 15)

top <- c(0,38,56,121,135)
bot <- c(30,56,121,135,'')
hzname <- c('A', 'Bt1', 'Bt2', 'Bk', 'R')
d <- data.frame(hzname, top, bot)
d

## # not run
## library(soilDB)
## help(soilDB)
## 
## # for links to lots of great examples look here!
## library(aqp)
## help(aqp)

options(width=95, stringsAsFactors=FALSE)
library(soilDB)
library(aqp)

# load example dataset
data(gopheridge)

# what kind of object is this?
class(gopheridge)

# what does the internal structure look like?
str(gopheridge, 2)

# let's take a look at the fields at the site and horizon levels within the SPC
siteNames(gopheridge)
horizonNames(gopheridge)

par(mar=c(1,1,1,1))
# ommiting pedon IDs and horizon designations
plot(gopheridge, print.id=FALSE, name='', width=0.3)
title('Pedons from the `gopheridge` sample dataset', line=-0.5)

s <- site(gopheridge)
# show table of site data
knitr::kable(s[1:2, 1:10])
knitr::kable(s[1:2, 11:20])
knitr::kable(s[1:2, 21:28])
knitr::kable(s[1:2, 28:36])

# use the following to show the data in the R console
#head(site(gopheridge), 2) # show the first 2 lines of the site data

h <- horizons(gopheridge)
# show table of site data
knitr::kable(h[1:8, 1:10])
knitr::kable(h[1:8, 11:19])
#knitr::kable(h[1:2, 21:28])
#knitr::kable(h[1:2, 28:36])

# use the following to show the data in the R console
#head(horizons(gopheridge), 5) # show the first 5 rows of the horizon data

# load required libraries
library(soilDB)
library(aqp)

# load data from a NASIS selected set
pedons <- fetchNASIS(from = 'pedons')

# what kind of object is this?
class(pedons)

# how many pedons
length(pedons)

# let's take a look at the fields at the site and horizon levels within the SPC
siteNames(pedons)
horizonNames(pedons)

# look at the first 2 rows of site and horizon data
head(site(pedons), 2)
head(horizons(pedons), 2)

# plot the locations of the gopheridge pedons within R
# Steps:
# 1) subset to a new data frame
# 2) create a spatial points data frame (SPDF)
# 3) plot the data

# load libraries
library(sp)
library(mapview)

# subset standard WGS84 decimal degree coordinates from the gopheridge SPC by specifying column names
gopher.locations <- site(gopheridge)

# initialize coordinates in an SPDF
coordinates(gopher.locations) <- ~ x_std + y_std
# define coordinate system
proj4string(gopher.locations) <- '+proj=longlat +datum=WGS84'

# creat interactive map
mapview(gopher.locations, legend=FALSE, map.types='OpenStreetMap', label=gopher.locations$site_id)

## # load libraries
## library(aqp)
## library(soilDB)
## library(sp)
## library(mapview)
## 
## # get pedons from the selected set
## pedons <- fetchNASIS(from = 'pedons')
## 
## # subset standard WGS84 decimal degree coordinates from the
## # gopheridge SPC by specifying column names
## pedons.sp <- site(pedons)[, c('site_id', 'x_std', 'y_std')]
## nrow(pedons.sp)
## 
## # remove any sites lacking standard lat/long coordinates
## # notice that there may now be fewer rows of data
## pedons.sp <- na.omit(pedons.sp)
## nrow(pedons.sp)
## 
## # initialize coordinates in an SPDF
## coordinates(pedons.sp) <- ~ x_std + y_std
## # define coordinate system
## proj4string(pedons.sp) <- '+proj=longlat +datum=WGS84'
## 
## # plot
## mapview(pedons.sp, legend=FALSE, map.types='OpenStreetMap', label=pedons.sp$site_id)

# summarize which soil taxa we have loaded
table(pedons$taxonname)
# sort results in descending order
sort(table(pedons$taxonname), decreasing=TRUE)

# could do the same thing for taxonomic subgroups or any column of the SPC at the site or horizon levels
table(pedons$taxsubgrp)
sort(table(pedons$taxsubgrp), decreasing=TRUE)

# table() is also useful when testing for null data using IS NA, is.na() or IS NOT NA, !is.na()
table(is.na(pedons$taxsubgrp))
table(!is.na(pedons$taxsubgrp))

# it can also be applied to horizon level columns in the SPC
sort(table(pedons$texture), decreasing=TRUE)

# say we wanted to look at what the variation of particle size classes are within a specific subgroup?
# use of grep() to filter and create an index, then apply that index to the SPC 
# and create a new SPC called 'f1' using the square bracket notation
idx <- grep('lithic', pedons$taxsubgrp, invert=FALSE)
# save this subset of 'lithic' soils for later use  
subset1 <- pedons[idx, ]
# or use the index directly to summarize a field
sort(table(pedons$taxpartsize[idx]), decreasing=TRUE)

# adjust margins
par(mar=c(1,0,0,1))
# plot the first 10 profiles of subset1
# limit plotting to a depth of about 60cm
plot(subset1[1:10, ], label='site_id', max.depth=60)
title('Pedons with the word "lithic" at subgroup-level of Soil Taxonomy', line=-2)

# say we wanted to look at what the variation of particle size classes are within a specific subgroup?
# first: use grep to pattern match the tax_subgroup field for the string 'aqu'
idx <- grep('lithic', pedons$taxsubgrp)
# save this subset
subset1 <- pedons[idx, ]
# check taxonomic range of particle size classes in the data
sort(table(subset1$taxsubgrp), decreasing=TRUE)
sort(table(subset1$taxpartsize), decreasing=TRUE)

# then further query the subset for only those profiles with particle size class of 'sandy-skeletal'
# notice: a double equal sign '==' is used for exact character or numeric criteria
idx <- which(subset1$taxpartsize == 'loamy')
# save this subset
subset2 <- subset1[idx, ]
table(subset2$taxpartsize)
# plot  profiles 1 thru 10
par(mar=c(0,0,2,1))
plot(subset2, label='site_id')
title('Loamy particle size control section class')

# extract site data from SPC into dataframe 's'
s <- site(pedons)
names(s)
# extract horizon data from SPC into dataframe 'h'
h <- horizons(pedons)
names(h)

## # use each one of these to return a vector of the pedons where errors were detected
## #get('sites.missing.pedons', envir=soilDB.env)
## #get('dup.pedon.ids', envir=soilDB.env)
## #get('bad.pedon.ids', envir=soilDB.env)
## # example of pedon_id's returned
## #[1] "2011MT0810001" "2011MT0810009" "2011MT0810015" "2011MT0810027" "2011MT0810034"
## 
## #get('bad.horizons', envir=soilDB.env)
## 
## # How could you then remove these from your SPC?
## # since the get() returns the string of bad pedon id's we can use a which() to query any pedon id's that don't match the bad id's
## idx <- which(! pedons$pedon_id %in% get('bad.pedon.ids', envir=soilDB.env))
## pedons <- pedons[idx, ]

# make a new object with a sequence of values from 1 to 10
a <- seq(from=1, to=10, by=1)
# result
#[1]  1  2  3  4  5  6  7  8  9 10

# define a function that performs a simple action on a vector of numbers
# "i" is a temporary object created inside of the context of this function based on the argument supplied
aFunction <- function(i) {
  # do something
  res <- i * 10
  # send the results back to the calling context
  return(res)
}

# apply our new function to object "a"
aFunction(a)

# load required libraries
library(aqp)
library(soilDB)

# load example dataset
data(gopheridge)

# the argument 'i' is a single soil profile
findBtHorizons <- function(i) {
  # extract horizons for current profile
  h <- horizons(i) 
  # search for pattern 't' in horizon designations
  idx <- grep('t', h$hzname)
  # subset these horizons
  h2 <- h[idx, ] 
  # subset columns in resulting dataframe
  res <- h2[, c('peiid', 'hzname', 'hzdept', 'hzdepb', 'clay', 'phfield')]
  # return data
  return(res)
}

# apply function to a single profile as a demonstration
findBtHorizons(gopheridge[1, ])

Bt.horizons <- profileApply(gopheridge, FUN=findBtHorizons, frameify = TRUE)

# apply a function by group
Bt.horizons.top <- aggregate(hzdept ~ peiid, data = Bt.horizons, FUN = min, na.rm=TRUE)

head(Bt.horizons.top)
names(Bt.horizons.top)[2] <- 'depth_to_Bt_cm'

# since we have peiid in the 'Bt.horizons.top' dataframe we can easy join it back to site data in the SPC
# NOTE: when used in conjunction with site(), the assignment operator will perform a left-join
site(gopheridge) <- Bt.horizons.top

# summary of depth to argillic in the data using a histogram
# reset figure margins
par(mar=c(4.5,4.5,1,1))
hist(gopheridge$depth_to_Bt_cm, xlab='Depth to Bt Horizon (cm)', main='')

# index to the first 15 profiles
idx <- 1:15

# reset figure margins
par(mar=c(0,0.5,3,1))

# plot indexed profiles, omitting IDs
plot(gopheridge[idx, ], print.id=FALSE)

# add the top depth of the first "Bt" horizon
points(x=1:15, y=gopheridge$depth_to_Bt_cm[idx], pch=21, bg='black', col='white')

# title / subtitle
title(main = "Select pedons from the 'gopheridge' sample dataset", line=-0.5)
title(sub= "Depth to first 'Bt' horizon identified", line=-2)

## # This time we'll go after the thickness of the organic horizons where present.
## 
## # load library
## library(plyr)
## 
## f.organic <- function(i) {
##   # extract horizons
##   h <- horizons(i)
##   # pattern match for 'O' horizon designations in horizon data
##   idx <- grep('O', h$hzname)
##   h2 <- h[idx, ]
##   # subset results
##   res <- h2[, c('peiid', 'phiid', 'hzname', 'hzdept', 'hzdepb')]
##   # return data
##   return(res)
## }
## 
## # apply function to each profile, results are a list of data.frames
## l <- profileApply(f, FUN=f.organic, simplify=FALSE)
## 
## # convert list into a dataframe
## organic <- ldply(l)
## 
## # show contents of the 'organic' dataframe
## head(organic)
## 
## # summarize this dataframe down to one max bottom depth value for each profile
## organic1 <- ddply(organic, 'peiid', summarise, organic_thickness_cm=max(hzdepb))
## 
## # since we have peiid in the 'organic1' dataframe we can join back to site data in the SPC
## site(f) <- organic1
## 
## # summary of organic thickness in the data
## # reset figure margins
## par(mar=c(4.5,4.5,1,1))
## hist(pedons$organic_thickness_cm, xlab='Thickness of Organic horizons (cm)', main='')

## # load required libraries
## library(plyr)
## 
## # the argument 'i' is a single soil profile
## f.limy <- function(i) {
##   # extract horizons for current profile
##   h <- horizons(i)
##   # search for pattern 'k' in horizon designations
##   idx <- grep('k', h$hzname)
##   # subset these horizons
##   h2 <- h[idx, ]
##   # subset columns in resulting dataframe
##   res <- h2[, c('peiid', 'phiid', 'hzname', 'hzdept', 'hzdepb', 'phfield', 'effclass')]
##   # return data
##   return(res)
## }
## 
## # apply function to each profile, results are a list of dataframes
## l <- profileApply(f, FUN=f.limy, simplify=FALSE)
## 
## # convert list into a dataframe, dropping all pedons with no 'k' horizons
## limy <- ldply(l)
## 
## # view the top 6 rows
## head(limy)
## 
## # still need to reduce this down to one depth value for each profile
## ## ddply() will apply a function (summarise the min(hzdept)) then combine the results into a data frame.
## ## standard ddply syntax is as follows (type '??ddply' into the R console):
## ## ddply(.data, .variables, .fun = NULL....)
## 
## limy1 <- ddply(limy, 'peiid', summarise, depth_to_carbonates_cm=min(hzdept))
## 
## # since we have peiid in the 'limy1' dataframe we can easy join it back to site data in the SPC
## # this won't work if there were no horizons with 'k' suffice
## site(f) <- limy1
## 
## # summary of depth to carbonates in the data using a histogram
## # reset figure margins
## par(mar=c(4.5,4.5,1,1))
## hist(pedons$depth_to_carbonates_cm, xlab='Depth to Calcium Carbonates (cm)', main='')

# fetch extended site and horizon data
e <- get_extended_data_from_NASIS_db()

### site and pedon related extended data
# vegetation data summary
colnames(e$ecositehistory) 

# diagnostic features
colnames(e$diagnostic) 

# surface rock fragments
colnames(e$surf_frag_summary)

# geomorphic description
colnames(e$geomorph)

# taxonomic history data
colnames(e$taxhistory)

# linked photo stored in site textnotes
colnames(e$photo) 

# site parent materials
colnames(e$pm)

### horizon related extended data
# rock fragments 
colnames(e$frag_summary) 

# soil texture modifers
colnames(e$texmodifier)

# soil structure data
colnames(e$struct) 

# graphically tabulate the occurrence of landforms
# load required libraries
library(soilDB)
# required for dotchart2()
library(Hmisc)

# load data from a NASIS selected set
pedons <- fetchNASIS(from = 'pedons')

# create 'lf' object of landform factors sorted in descending order
lf <- sort(table(pedons$landform_string), decreasing = TRUE)

# plot top 10 or length, whichever is shorter
dotchart2(lf[1:pmin(10, length(lf))], col='black', xlim = c(0, max(lf)), cex.labels = 0.75)

# rename gopheridge data
f <- gopheridge

# get diagnostic features associated with pedons loaded from selected set
d <- diagnostic_hz(f)

# summary of the diagnostic features in your data!
unique(d$featkind)
sort(table(droplevels(factor(d$featkind))), decreasing = TRUE)

# subset argillic horizons
d <- d[d$featkind == 'argillic horizon', ]

# create a new column and subtract the upper from the lower depth
d$argillic_thickness_cm <- d$featdepb - d$featdept

# create another new column with the upper depth to the diagnostic feature
d$depth_to_argillic_cm <- d$featdept

# omit NA values
d <- na.omit(d)

# subset to pedon records IDs and calculated thickness
d <- d[, c('peiid', 'argillic_thickness_cm', 'depth_to_argillic_cm')]
head(d)

# join these data with existing site data
site(f) <- d

# plot as histogram
# reset figure margins
par(mar = c(4.5,4.5,1,1))
hist(pedons$argillic_thickness_cm, xlab = 'Thickness of argillic diagnostic (cm)', main='')
hist(pedons$depth_to_argillic_cm, xlab = 'Depth to argillic diagnostic (cm)', main = '')

# start fresh with your own data
f <- fetchNASIS(from = 'pedons')
# get diagnostic features associated with pedons loaded from selected set
d <- diagnostic_hz(f)
# summary of the diagnostic features in your data!
unique(d$featkind)
# top 5 most frequent
sort(table(d$featkind), decreasing = TRUE)[1:5]

# subset argillic horizons - or choose your own diagnostic feature and modify this script!
#idx <- which(d$diag_kind == 'your_diagnostic')
#d <- d[idx, ]

# how would you do the rest.....see if you can work it out!


## work up diagnostic plot based on gopheridge dataset
library(aqp)
library(soilDB)
library(sharpshootR)

# load data
data(gopheridge)

# can limit which diagnostic features to show by setting 'v' manually
v <- c('ochric.epipedon', 'cambic.horizon', 'argillic.horizon', 'paralithic.contact', 'lithic.contact')

# generate diagnostic property diagram
diagnosticPropertyPlot(gopheridge, v, k=5, grid.label='site_id', dend.label = 'taxonname', sort.vars = FALSE)

# plot again, this time with diagnostic features ordered according to co-occurrence
diagnosticPropertyPlot(gopheridge, v, k=5, grid.label='site_id', dend.label = 'taxonname', sort.vars = TRUE)

## library(soilDB)
## library(sharpshootR)
## 
## # load data
## f <- fetchNASIS(from = 'pedons')
## 
## # may need to subset to a particular series or taxa here....to reduce the number of pedons!
## 
## # select a series of diagnostic properties or automatically pull diagnostic feature columns
## # get all diagnostic feature columns from site data by pattern matching on '[.]' in the colnames
## idx <- grep('[.]', colnames(site(f)))
## v <- colnames(site(f))[idx]
## v
## 
## # or insert diagnostics of interest found in your data here from the list of possible diagnostics in 'v'
## v <- c('ochric.epipedon', 'cambic.horizon', 'argillic.horizon', 'paralithic.contact', 'lithic.contact')
## 
## # generate diagnostic property diagram
## diagnosticPropertyPlot(f, v, k=5, grid.label='site_id', dend.label = 'taxonname')

library(RODBC)

# write query as a long text object
q <- "
-- columns to return
SELECT siteiid as siteiid, peiid, usiteid as site_id, upedonid as pedon_id, obsdate as obs_date,
soitemp, soitempdep

FROM
-- tables that are queried and join conditions
site_View_1 
INNER JOIN siteobs_View_1 ON site_View_1.siteiid = siteobs_View_1.siteiidref
LEFT OUTER JOIN sitesoiltemp_View_1 ON siteobs_View_1.siteobsiid = sitesoiltemp_View_1.siteobsiidref
LEFT OUTER JOIN pedon_View_1 ON siteobs_View_1.siteobsiid = pedon_View_1.siteobsiidref
-- ordering of rows
ORDER BY obs_date, siteiid;"

# setup connection local NASIS
channel <- odbcDriverConnect(connection = getOption("soilDB.NASIS.credentials"))

# exec query
d <- sqlQuery(channel, q, stringsAsFactors=FALSE)

# close connection
odbcClose(channel)

# check results
str(d)

# remove records missing values
d <- na.omit(d)

# tabulate unique soil depths
table(d$soitempdep)

# extract doy of year
d$doy <- as.integer(format(d$obs_date, "%j"))

# when where measurements collected?
hist(d$doy, xlim=c(1,366), breaks=30, las=1, main='Soil Temperature Measurements', xlab='Day of Year')

# soil temperature by day of year
plot(soitemp ~ doy, data=d, type='p', xlim=c(1, 366), ylim=c(-1, 25), xlab='Day of Year', ylab='Soil Temperature at 50cm (deg C)', las=1)
